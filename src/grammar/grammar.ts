// import { GrammarDefinition, Pattern, RegexOrString } from './grammarDefinition';
// import { isPatternInclude, isPatternMatch, isPatternBeginEnd, scope } from './pattern';
// import { XRegExp } from 'xregexp';
// import { TokenizerState } from './tokenize';

// const maxDepth = 10;

// export class Grammar {
//     constructor(private grammarDef: GrammarDefinition) {}

//     tokenizeLine(line: string, state?: TokenizerState) {
//     }
// }

